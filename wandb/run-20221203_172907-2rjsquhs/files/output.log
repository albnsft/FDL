==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─IntermediateLayerGetter: 1-1           [[-1, 2048, 25, 19]]      --
|    └─Conv2d: 2-1                       [-1, 64, 100, 75]         9,408
|    └─BatchNorm2d: 2-2                  [-1, 64, 100, 75]         128
|    └─ReLU: 2-3                         [-1, 64, 100, 75]         --
|    └─MaxPool2d: 2-4                    [-1, 64, 50, 38]          --
|    └─Sequential: 2-5                   [-1, 256, 50, 38]         --
|    |    └─Bottleneck: 3-1              [-1, 256, 50, 38]         75,008
|    |    └─Bottleneck: 3-2              [-1, 256, 50, 38]         70,400
|    |    └─Bottleneck: 3-3              [-1, 256, 50, 38]         70,400
|    └─Sequential: 2-6                   [-1, 512, 25, 19]         --
|    |    └─Bottleneck: 3-4              [-1, 512, 25, 19]         379,392
|    |    └─Bottleneck: 3-5              [-1, 512, 25, 19]         280,064
|    |    └─Bottleneck: 3-6              [-1, 512, 25, 19]         280,064
|    |    └─Bottleneck: 3-7              [-1, 512, 25, 19]         280,064
|    └─Sequential: 2-7                   [-1, 1024, 25, 19]        --
|    |    └─Bottleneck: 3-8              [-1, 1024, 25, 19]        1,512,448
|    |    └─Bottleneck: 3-9              [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-10             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-11             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-12             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-13             [-1, 1024, 25, 19]        1,117,184
|    └─Sequential: 2-8                   [-1, 2048, 25, 19]        --
|    |    └─Bottleneck: 3-14             [-1, 2048, 25, 19]        6,039,552
|    |    └─Bottleneck: 3-15             [-1, 2048, 25, 19]        4,462,592
|    |    └─Bottleneck: 3-16             [-1, 2048, 25, 19]        4,462,592
├─DeepLabHead: 1-2                       [-1, 21, 25, 19]          --
|    └─ASPP: 2-9                         [-1, 256, 25, 19]         --
|    |    └─Sequential: 3-17             [-1, 256, 25, 19]         328,192
|    └─Conv2d: 2-10                      [-1, 256, 25, 19]         589,824
|    └─BatchNorm2d: 2-11                 [-1, 256, 25, 19]         512
|    └─ReLU: 2-12                        [-1, 256, 25, 19]         --
|    └─Conv2d: 2-13                      [-1, 21, 25, 19]          5,397
├─FCNHead: 1-3                           [-1, 21, 25, 19]          --
|    └─Conv2d: 2-14                      [-1, 256, 25, 19]         2,359,296
|    └─BatchNorm2d: 2-15                 [-1, 256, 25, 19]         512
|    └─ReLU: 2-16                        [-1, 256, 25, 19]         --
|    └─Dropout: 2-17                     [-1, 256, 25, 19]         --
|    └─Conv2d: 2-18                      [-1, 21, 25, 19]          5,397
==========================================================================================
Total params: 26,797,162
Trainable params: 26,797,162
Non-trainable params: 0
Total mult-adds (G): 11.90
==========================================================================================
Input size (MB): 0.34
Forward/backward pass size (MB): 205.08
Params size (MB): 102.22
Estimated Total Size (MB): 307.65
==========================================================================================
torch.Size([4, 200, 150])
torch.Size([4, 200, 150])
Traceback (most recent call last):
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 570, in <module>
    Net.fit()
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 452, in fit
    train_loss_mean = self.__train_model()
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 400, in __train_model
    loss.backward()
  File "C:\Users\alban\PycharmProjects\FDL\venv\lib\site-packages\torch\_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "C:\Users\alban\PycharmProjects\FDL\venv\lib\site-packages\torch\autograd\__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
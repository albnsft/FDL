==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─IntermediateLayerGetter: 1-1           [[-1, 2048, 25, 19]]      --
|    └─Conv2d: 2-1                       [-1, 64, 100, 75]         9,408
|    └─BatchNorm2d: 2-2                  [-1, 64, 100, 75]         128
|    └─ReLU: 2-3                         [-1, 64, 100, 75]         --
|    └─MaxPool2d: 2-4                    [-1, 64, 50, 38]          --
|    └─Sequential: 2-5                   [-1, 256, 50, 38]         --
|    |    └─Bottleneck: 3-1              [-1, 256, 50, 38]         75,008
|    |    └─Bottleneck: 3-2              [-1, 256, 50, 38]         70,400
|    |    └─Bottleneck: 3-3              [-1, 256, 50, 38]         70,400
|    └─Sequential: 2-6                   [-1, 512, 25, 19]         --
|    |    └─Bottleneck: 3-4              [-1, 512, 25, 19]         379,392
|    |    └─Bottleneck: 3-5              [-1, 512, 25, 19]         280,064
|    |    └─Bottleneck: 3-6              [-1, 512, 25, 19]         280,064
|    |    └─Bottleneck: 3-7              [-1, 512, 25, 19]         280,064
|    └─Sequential: 2-7                   [-1, 1024, 25, 19]        --
|    |    └─Bottleneck: 3-8              [-1, 1024, 25, 19]        1,512,448
|    |    └─Bottleneck: 3-9              [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-10             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-11             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-12             [-1, 1024, 25, 19]        1,117,184
|    |    └─Bottleneck: 3-13             [-1, 1024, 25, 19]        1,117,184
|    └─Sequential: 2-8                   [-1, 2048, 25, 19]        --
|    |    └─Bottleneck: 3-14             [-1, 2048, 25, 19]        6,039,552
|    |    └─Bottleneck: 3-15             [-1, 2048, 25, 19]        4,462,592
|    |    └─Bottleneck: 3-16             [-1, 2048, 25, 19]        4,462,592
├─DeepLabHead: 1-2                       [-1, 25, 25, 19]          --
|    └─ASPP: 2-9                         [-1, 256, 25, 19]         --
|    |    └─Sequential: 3-17             [-1, 256, 25, 19]         328,192
|    └─Conv2d: 2-10                      [-1, 256, 25, 19]         589,824
|    └─BatchNorm2d: 2-11                 [-1, 256, 25, 19]         512
|    └─ReLU: 2-12                        [-1, 256, 25, 19]         --
|    └─Conv2d: 2-13                      [-1, 25, 25, 19]          6,425
├─FCNHead: 1-3                           [-1, 21, 25, 19]          --
|    └─Conv2d: 2-14                      [-1, 256, 25, 19]         2,359,296
|    └─BatchNorm2d: 2-15                 [-1, 256, 25, 19]         512
|    └─ReLU: 2-16                        [-1, 256, 25, 19]         --
|    └─Dropout: 2-17                     [-1, 256, 25, 19]         --
|    └─Conv2d: 2-18                      [-1, 21, 25, 19]          5,397
==========================================================================================
Total params: 26,798,190
Trainable params: 26,798,190
Non-trainable params: 0
Total mult-adds (G): 11.90
==========================================================================================
Input size (MB): 0.34
Forward/backward pass size (MB): 205.10
Params size (MB): 102.23
Estimated Total Size (MB): 307.67
==========================================================================================
*****************************training*************************
Loss is 0.955524206161499
Acc is [0.037844444444444444]
Loss is 0.8725312352180481
Acc is [0.037844444444444444, 0.24824444444444443]
Loss is 0.7916466593742371
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554]
Loss is 0.9663165211677551
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238]
Loss is 0.7767855525016785
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775]
Loss is 0.655704915523529
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553]
Loss is 0.8921882510185242
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112]
Loss is 0.891676127910614
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444]
Loss is 0.6937232613563538
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111]
Loss is 0.8897690176963806
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556]
Loss is 0.8730620741844177
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668]
Loss is 0.7941603064537048
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778]
Loss is 0.9009685516357422
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334]
Loss is 0.49456787109375
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445]
Loss is 0.6650461554527283
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776]
Loss is 0.7673463821411133
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888]
Loss is 0.7961013913154602
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776]
Loss is 0.7201301455497742
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778]
Loss is 0.6559799313545227
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778, 0.34442222222222224]
Loss is 0.921448290348053
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778, 0.34442222222222224, 0.07852222222222222]
Loss is 0.6969628930091858
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778, 0.34442222222222224, 0.07852222222222222, 0.3027111111111111]
Loss is 0.8642182350158691
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778, 0.34442222222222224, 0.07852222222222222, 0.3027111111111111, 0.13575555555555555]
Loss is 0.5486995577812195
Acc is [0.037844444444444444, 0.24824444444444443, 0.27065555555555554, 0.0238, 0.26197777777777775, 0.34075555555555553, 0.10371111111111112, 0.09884444444444444, 0.2725111111111111, 0.07955555555555556, 0.12566666666666668, 0.20247777777777778, 0.09963333333333334, 0.5072444444444445, 0.33697777777777776, 0.23228888888888888, 0.20517777777777776, 0.2798777777777778, 0.34442222222222224, 0.07852222222222222, 0.3027111111111111, 0.13575555555555555, 0.4514222222222222]
Loss is 0.8601710200309753

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─MobileNetV2Encoder: 1-1                     [-1, 3, 192, 160]         --
|    └─Sequential: 2                          []                        --
|    |    └─Conv2dNormActivation: 3-1         [-1, 32, 96, 80]          928
|    |    └─InvertedResidual: 3-2             [-1, 16, 96, 80]          896
|    |    └─InvertedResidual: 3-3             [-1, 24, 48, 40]          5,136
|    |    └─InvertedResidual: 3-4             [-1, 24, 48, 40]          8,832
|    |    └─InvertedResidual: 3-5             [-1, 32, 24, 20]          10,000
|    |    └─InvertedResidual: 3-6             [-1, 32, 24, 20]          14,848
|    |    └─InvertedResidual: 3-7             [-1, 32, 24, 20]          14,848
|    |    └─InvertedResidual: 3-8             [-1, 64, 12, 10]          21,056
|    |    └─InvertedResidual: 3-9             [-1, 64, 12, 10]          54,272
|    |    └─InvertedResidual: 3-10            [-1, 64, 12, 10]          54,272
|    |    └─InvertedResidual: 3-11            [-1, 64, 12, 10]          54,272
|    |    └─InvertedResidual: 3-12            [-1, 96, 12, 10]          66,624
|    |    └─InvertedResidual: 3-13            [-1, 96, 12, 10]          118,272
|    |    └─InvertedResidual: 3-14            [-1, 96, 12, 10]          118,272
|    |    └─InvertedResidual: 3-15            [-1, 160, 6, 5]           155,264
|    |    └─InvertedResidual: 3-16            [-1, 160, 6, 5]           320,000
|    |    └─InvertedResidual: 3-17            [-1, 160, 6, 5]           320,000
|    |    └─InvertedResidual: 3-18            [-1, 320, 6, 5]           473,920
|    |    └─Conv2dNormActivation: 3-19        [-1, 1280, 6, 5]          412,160
├─FPNDecoder: 1-2                             [-1, 128, 48, 40]         --
|    └─Conv2d: 2-1                            [-1, 256, 6, 5]           327,936
|    └─FPNBlock: 2-2                          [-1, 256, 12, 10]         --
|    |    └─Conv2d: 3-20                      [-1, 256, 12, 10]         24,832
|    └─FPNBlock: 2-3                          [-1, 256, 24, 20]         --
|    |    └─Conv2d: 3-21                      [-1, 256, 24, 20]         8,448
|    └─FPNBlock: 2-4                          [-1, 256, 48, 40]         --
|    |    └─Conv2d: 3-22                      [-1, 256, 48, 40]         6,400
|    └─ModuleList: 2                          []                        --
|    |    └─SegmentationBlock: 3-23           [-1, 128, 48, 40]         590,592
|    |    └─SegmentationBlock: 3-24           [-1, 128, 48, 40]         442,880
|    |    └─SegmentationBlock: 3-25           [-1, 128, 48, 40]         295,168
|    |    └─SegmentationBlock: 3-26           [-1, 128, 48, 40]         295,168
|    └─MergeBlock: 2-5                        [-1, 128, 48, 40]         --
|    └─Dropout2d: 2-6                         [-1, 128, 48, 40]         --
├─SegmentationHead: 1-3                       [-1, 25, 192, 160]        --
|    └─Conv2d: 2-7                            [-1, 25, 48, 40]          3,225
|    └─UpsamplingBilinear2d: 2-8              [-1, 25, 192, 160]        --
|    └─Activation: 2-9                        [-1, 25, 192, 160]        --
|    |    └─Identity: 3-27                    [-1, 25, 192, 160]        --
===============================================================================================
Total params: 4,218,521
Trainable params: 4,218,521
Non-trainable params: 0
Total mult-adds (M): 65.06
===============================================================================================
Input size (MB): 0.35
Forward/backward pass size (MB): 9.68
Params size (MB): 16.09
Estimated Total Size (MB): 26.13
===============================================================================================
Epoch [1] took 85.57s | train_loss: 0.7145, train_acc: 0.2866, val_loss: 0.6797, val_acc: 0.3200
Epoch [2] took 86.13s | train_loss: 0.6530, train_acc: 0.3474, val_loss: 0.6653, val_acc: 0.3350
Validation - Loss: 0.5532325506210327 | Accuracy: 0.44850260416666665
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Traceback (most recent call last):
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 682, in <module>
    main(model, encoder)
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 649, in main
    pred_mask_test = Net.predict(data.test_dataloader)
  File "C:\Users\alban\PycharmProjects\FDL\Kaggle\main.py", line 528, in predict
    assert(isinstance(data, Dataset) and isinstance(index_image, int))
AssertionError